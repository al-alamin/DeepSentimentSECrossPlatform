{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from django.conf import settings\n",
    "import cPickle as pickle\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sys.path.append('c:\\dev\\opinion\\opinion\\python\\opinion')\n",
    "import utils.fileutils as fileutils\n",
    "import utils.metrics as metrics\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = r\"C:\\dev\\opinion\\papers\\sentiplus\"\n",
    "indir = os.path.join(rootdir, \"Hybrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hot Encode DSOSE values and then Change the previous Base file into the new one\n",
    "#infile = os.path.join(indir, \"DSOSE_ResultsConsolidated_RF.xls\")\n",
    "infile = os.path.join(indir, \"ConsolidatedWithBestTrainedClfsFromThreeSETools.xls\")\n",
    "\n",
    "df = pd.read_excel(infile, \"Sheet1\", encoding=\"ISO-8859-1\")\n",
    "dsoseHotEncodes = []\n",
    "for index, row in df.iterrows():\n",
    "    dsose = row[\"DSOSE\"]\n",
    "    if dsose == \"p\":\n",
    "        dsoseHotEncodes.append(1)\n",
    "    elif dsose == \"n\":\n",
    "        dsoseHotEncodes.append(-1)\n",
    "    else:\n",
    "        dsoseHotEncodes.append(0)\n",
    "df[\"DSOSE_HotEncoded\"] = (pd.Series(dsoseHotEncodes)).values\n",
    "df.to_excel(infile, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computePerformanceOverallOfLearner(infile, learnerCol, filenames):\n",
    "    #infile = os.path.join(indir, \"ResultsConsolidated_\"+algo+\".xls\")\n",
    "    df = fileutils.readExcel(infile, \"Sheet1\", encoding=\"ISO-8859-1\")\n",
    "    exps = []\n",
    "    gots = []\n",
    "    labels = set()\n",
    "    for index, row in df.iterrows():\n",
    "        fname = row[\"File\"]\n",
    "        fname = fname.split(\"_\")[0]\n",
    "        if fname not in filenames:\n",
    "                #print fname, \" not in filenmaes\"\n",
    "                #return\n",
    "                continue\n",
    "        else:\n",
    "                exp = row[\"ManualLabel\"]\n",
    "                got = row[learnerCol]\n",
    "                labels.add(exp)\n",
    "                exps.append(exp)\n",
    "                gots.append(got)\n",
    "    computer = metrics.PerformanceMultiClass(exps, gots, labels = list(labels))\n",
    "    for label in labels:\n",
    "            pr = computer.precision(label)\n",
    "            re = computer.recall(label)\n",
    "            f1 = 2*pr*re/(pr+re)\n",
    "            print \"Label = %s. Precision = %.3f. Recall = %.3f. F1 = %.3f\"%(label, pr, re, f1)\n",
    "    f1_macro = computer.f1_macro_average()\n",
    "    pr_macro = computer.precision_macro_average()\n",
    "    rec_macro = computer.recall_macro_average()\n",
    "    f1_micro, _, _ = computer.compute_micro_average()\n",
    "    print \"F1 Macro = %.3f. Micro = %.3f\"%(f1_macro, f1_micro)\n",
    "    print \"Macro Precision = %.3f. Recall = %.3f\"%(pr_macro, rec_macro)\n",
    "    print \"-------------------------------\"\n",
    "\n",
    "def computePerformancOfLearner(infile, learnerCol, filenames):\n",
    "    #infile = os.path.join(indir, \"ResultsConsolidated_\"+algo+\".xls\")\n",
    "    df = fileutils.readExcel(infile, \"Sheet1\", encoding=\"ISO-8859-1\")\n",
    "    exps = dict()\n",
    "    gots = dict()\n",
    "    labels = dict()\n",
    "    for index, row in df.iterrows():\n",
    "        fname = row[\"File\"]\n",
    "        fname = fname.split(\"_\")[0]\n",
    "        if fname not in filenames:\n",
    "                #print fname, \" not in filenmaes\"\n",
    "                continue\n",
    "        else:\n",
    "                if fname not in exps:\n",
    "                    exps[fname] = []\n",
    "                    gots[fname] = []\n",
    "                    labels[fname] = set()\n",
    "        exp = row[\"ManualLabel\"]\n",
    "        got = row[learnerCol]\n",
    "        labels[fname].add(exp)\n",
    "        exps[fname].append(exp)\n",
    "        gots[fname].append(got)\n",
    "    for fname in filenames:\n",
    "        computer = metrics.PerformanceMultiClass(exps[fname], gots[fname], labels = list(labels[fname]))\n",
    "        for label in labels[fname]:\n",
    "                pr = computer.precision(label)\n",
    "                re = computer.recall(label)\n",
    "                f1 = 2*pr*re/(pr+re)\n",
    "                print \"File %s. Label = %s. Precision = %.2f. Recall = %.2f. F1 = %.2f\"%(fname, label, pr, re, f1)\n",
    "        f1_macro = computer.f1_macro_average()\n",
    "        f1_micro, _, _ = computer.compute_micro_average()\n",
    "        print \"File = %s. F1 Macro = %.2f. Micro = %.2f\"%(fname, f1_macro, f1_micro)\n",
    "        print \"-------------------------------\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [\"DatasetLinJIRA\", \"BenchmarkUddinSO\", \"DatasetLinAppReviews\", \n",
    "                     \"DatasetLinSO\", \"DatasetSenti4SDSO\", \"OrtuJIRA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DsoLabelFullTextW2V : Overall Performance\n",
      "--------------------------------------------------------------------------------\n",
      "Label = p. Precision = 0.442. Recall = 0.540. F1 = 0.486\n",
      "Label = o. Precision = 0.665. Recall = 0.627. F1 = 0.645\n",
      "Label = n. Precision = 0.528. Recall = 0.469. F1 = 0.497\n",
      "F1 Macro = 0.545. Micro = 0.572\n",
      "Macro Precision = 0.545. Recall = 0.545\n",
      "-------------------------------\n",
      "DsoLabelFullTextW2V : By File Performance\n",
      "--------------------------------------------------------------------------------\n",
      "File DatasetLinJIRA. Label = p. Precision = 0.58. Recall = 0.95. F1 = 0.72\n",
      "File DatasetLinJIRA. Label = n. Precision = 0.98. Recall = 0.83. F1 = 0.90\n",
      "File = DatasetLinJIRA. F1 Macro = 0.83. Micro = 0.85\n",
      "-------------------------------\n",
      "File BenchmarkUddinSO. Label = p. Precision = 0.34. Recall = 0.50. F1 = 0.40\n",
      "File BenchmarkUddinSO. Label = o. Precision = 0.68. Recall = 0.63. F1 = 0.65\n",
      "File BenchmarkUddinSO. Label = n. Precision = 0.37. Recall = 0.25. F1 = 0.30\n",
      "File = BenchmarkUddinSO. F1 Macro = 0.46. Micro = 0.53\n",
      "-------------------------------\n",
      "File DatasetLinAppReviews. Label = p. Precision = 0.73. Recall = 0.89. F1 = 0.80\n",
      "File DatasetLinAppReviews. Label = o. Precision = 0.14. Recall = 0.32. F1 = 0.19\n",
      "File DatasetLinAppReviews. Label = n. Precision = 0.91. Recall = 0.41. F1 = 0.56\n",
      "File = DatasetLinAppReviews. F1 Macro = 0.57. Micro = 0.66\n",
      "-------------------------------\n",
      "File DatasetLinSO. Label = p. Precision = 0.25. Recall = 0.62. F1 = 0.36\n",
      "File DatasetLinSO. Label = o. Precision = 0.89. Recall = 0.76. F1 = 0.82\n",
      "File DatasetLinSO. Label = n. Precision = 0.41. Recall = 0.39. F1 = 0.40\n",
      "File = DatasetLinSO. F1 Macro = 0.55. Micro = 0.70\n",
      "-------------------------------\n",
      "File DatasetSenti4SDSO. Label = p. Precision = 0.62. Recall = 0.71. F1 = 0.66\n",
      "File DatasetSenti4SDSO. Label = o. Precision = 0.59. Recall = 0.52. F1 = 0.55\n",
      "File DatasetSenti4SDSO. Label = n. Precision = 0.62. Recall = 0.61. F1 = 0.61\n",
      "File = DatasetSenti4SDSO. F1 Macro = 0.61. Micro = 0.61\n",
      "-------------------------------\n",
      "File OrtuJIRA. Label = p. Precision = 0.30. Recall = 0.34. F1 = 0.32\n",
      "File OrtuJIRA. Label = o. Precision = 0.72. Recall = 0.64. F1 = 0.67\n",
      "File OrtuJIRA. Label = n. Precision = 0.37. Recall = 0.49. F1 = 0.42\n",
      "File = OrtuJIRA. F1 Macro = 0.47. Micro = 0.56\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "infile = os.path.join(indir, \"ConsolidatedWithBestTrainedClfsFromThreeSETools.xls\")\n",
    "learnerCol = \"DsoLabelFullTextW2V\"\n",
    "print learnerCol, \": Overall Performance\"\n",
    "print \"-\"*80\n",
    "computePerformanceOverallOfLearner(infile, learnerCol, filenames)    \n",
    "print learnerCol, \": By File Performance\"\n",
    "print \"-\"*80\n",
    "computePerformancOfLearner(infile, learnerCol, filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DsoLabelFullText : Overall Performance\n",
      "--------------------------------------------------------------------------------\n",
      "Label = p. Precision = 0.467. Recall = 0.524. F1 = 0.494\n",
      "Label = o. Precision = 0.668. Recall = 0.684. F1 = 0.676\n",
      "Label = n. Precision = 0.577. Recall = 0.460. F1 = 0.512\n",
      "F1 Macro = 0.563. Micro = 0.597\n",
      "Macro Precision = 0.571. Recall = 0.556\n",
      "-------------------------------\n",
      "DsoLabelFullText : By File Performance\n",
      "--------------------------------------------------------------------------------\n",
      "File DatasetLinJIRA. Label = p. Precision = 0.60. Recall = 0.94. F1 = 0.73\n",
      "File DatasetLinJIRA. Label = n. Precision = 0.98. Recall = 0.84. F1 = 0.91\n",
      "File = DatasetLinJIRA. F1 Macro = 0.84. Micro = 0.86\n",
      "-------------------------------\n",
      "File BenchmarkUddinSO. Label = p. Precision = 0.36. Recall = 0.45. F1 = 0.40\n",
      "File BenchmarkUddinSO. Label = o. Precision = 0.67. Recall = 0.70. F1 = 0.69\n",
      "File BenchmarkUddinSO. Label = n. Precision = 0.43. Recall = 0.23. F1 = 0.30\n",
      "File = BenchmarkUddinSO. F1 Macro = 0.47. Micro = 0.56\n",
      "-------------------------------\n",
      "File DatasetLinAppReviews. Label = p. Precision = 0.75. Recall = 0.87. F1 = 0.81\n",
      "File DatasetLinAppReviews. Label = o. Precision = 0.15. Recall = 0.44. F1 = 0.23\n",
      "File DatasetLinAppReviews. Label = n. Precision = 0.96. Recall = 0.42. F1 = 0.58\n",
      "File = DatasetLinAppReviews. F1 Macro = 0.60. Micro = 0.66\n",
      "-------------------------------\n",
      "File DatasetLinSO. Label = p. Precision = 0.26. Recall = 0.53. F1 = 0.35\n",
      "File DatasetLinSO. Label = o. Precision = 0.88. Recall = 0.83. F1 = 0.85\n",
      "File DatasetLinSO. Label = n. Precision = 0.51. Recall = 0.35. F1 = 0.41\n",
      "File = DatasetLinSO. F1 Macro = 0.56. Micro = 0.74\n",
      "-------------------------------\n",
      "File DatasetSenti4SDSO. Label = p. Precision = 0.64. Recall = 0.71. F1 = 0.67\n",
      "File DatasetSenti4SDSO. Label = o. Precision = 0.59. Recall = 0.56. F1 = 0.58\n",
      "File DatasetSenti4SDSO. Label = n. Precision = 0.64. Recall = 0.62. F1 = 0.63\n",
      "File = DatasetSenti4SDSO. F1 Macro = 0.63. Micro = 0.62\n",
      "-------------------------------\n",
      "File OrtuJIRA. Label = p. Precision = 0.32. Recall = 0.34. F1 = 0.33\n",
      "File OrtuJIRA. Label = o. Precision = 0.72. Recall = 0.69. F1 = 0.70\n",
      "File OrtuJIRA. Label = n. Precision = 0.41. Recall = 0.48. F1 = 0.44\n",
      "File = OrtuJIRA. F1 Macro = 0.49. Micro = 0.59\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "infile = os.path.join(indir, \"ConsolidatedWithBestTrainedClfsFromThreeSETools.xls\")\n",
    "learnerCol = \"DsoLabelFullText\"\n",
    "print learnerCol, \": Overall Performance\"\n",
    "print \"-\"*80\n",
    "computePerformanceOverallOfLearner(infile, learnerCol, filenames)    \n",
    "print learnerCol, \": By File Performance\"\n",
    "print \"-\"*80\n",
    "computePerformancOfLearner(infile, learnerCol, filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senti4SD : Overall Performance\n",
      "--------------------------------------------------------------------------------\n",
      "Label = p. Precision = 0.773. Recall = 0.692. F1 = 0.731\n",
      "Label = o. Precision = 0.783. Recall = 0.865. F1 = 0.822\n",
      "Label = n. Precision = 0.748. Recall = 0.640. F1 = 0.690\n",
      "F1 Macro = 0.750. Micro = 0.774\n",
      "Macro Precision = 0.768. Recall = 0.732\n",
      "-------------------------------\n",
      "Senti4SD : By File Performance\n",
      "--------------------------------------------------------------------------------\n",
      "File DatasetLinJIRA. Label = p. Precision = 0.91. Recall = 0.94. F1 = 0.93\n",
      "File DatasetLinJIRA. Label = n. Precision = 0.97. Recall = 0.96. F1 = 0.97\n",
      "File = DatasetLinJIRA. F1 Macro = 0.95. Micro = 0.95\n",
      "-------------------------------\n",
      "File BenchmarkUddinSO. Label = p. Precision = 0.48. Recall = 0.29. F1 = 0.36\n",
      "File BenchmarkUddinSO. Label = o. Precision = 0.66. Recall = 0.85. F1 = 0.75\n",
      "File BenchmarkUddinSO. Label = n. Precision = 0.46. Recall = 0.27. F1 = 0.34\n",
      "File = BenchmarkUddinSO. F1 Macro = 0.50. Micro = 0.62\n",
      "-------------------------------\n",
      "File DatasetLinAppReviews. Label = p. Precision = 0.83. Recall = 0.89. F1 = 0.86\n",
      "File DatasetLinAppReviews. Label = o. Precision = 0.00. Recall = 0.00. F1 = nan\n",
      "File DatasetLinAppReviews. Label = n. Precision = 0.78. Recall = 0.83. F1 = 0.80\n",
      "File = DatasetLinAppReviews. F1 Macro = 0.55. Micro = 0.80\n",
      "-------------------------------\n",
      "File DatasetLinSO. Label = p. Precision = 0.56. Recall = 0.23. F1 = 0.32\n",
      "File DatasetLinSO. Label = o. Precision = 0.86. Recall = 0.95. F1 = 0.90\n",
      "File DatasetLinSO. Label = n. Precision = 0.55. Recall = 0.38. F1 = 0.45\n",
      "File = DatasetLinSO. F1 Macro = 0.58. Micro = 0.82\n",
      "-------------------------------\n",
      "File DatasetSenti4SDSO. Label = p. Precision = 0.90. Recall = 0.92. F1 = 0.91\n",
      "File DatasetSenti4SDSO. Label = o. Precision = 0.82. Recall = 0.78. F1 = 0.80\n",
      "File DatasetSenti4SDSO. Label = n. Precision = 0.79. Recall = 0.82. F1 = 0.80\n",
      "File = DatasetSenti4SDSO. F1 Macro = 0.84. Micro = 0.84\n",
      "-------------------------------\n",
      "File OrtuJIRA. Label = p. Precision = 0.74. Recall = 0.71. F1 = 0.73\n",
      "File OrtuJIRA. Label = o. Precision = 0.84. Recall = 0.89. F1 = 0.86\n",
      "File OrtuJIRA. Label = n. Precision = 0.70. Recall = 0.52. F1 = 0.60\n",
      "File = OrtuJIRA. F1 Macro = 0.73. Micro = 0.81\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\opinion2\\lib\\site-packages\\ipykernel_launcher.py:61: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "infile = os.path.join(indir, \"ConsolidatedWithBestTrainedClfsFromThreeSETools.xls\")\n",
    "learnerCol = \"Senti4SD\"\n",
    "print learnerCol, \": Overall Performance\"\n",
    "print \"-\"*80\n",
    "computePerformanceOverallOfLearner(infile, learnerCol, filenames)    \n",
    "print learnerCol, \": By File Performance\"\n",
    "print \"-\"*80\n",
    "computePerformancOfLearner(infile, learnerCol, filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentiCR : Overall Performance\n",
      "--------------------------------------------------------------------------------\n",
      "Label = p. Precision = 0.803. Recall = 0.667. F1 = 0.728\n",
      "Label = o. Precision = 0.767. Recall = 0.903. F1 = 0.830\n",
      "Label = n. Precision = 0.804. Recall = 0.599. F1 = 0.687\n",
      "F1 Macro = 0.756. Micro = 0.780\n",
      "Macro Precision = 0.791. Recall = 0.723\n",
      "-------------------------------\n",
      "SentiCR : By File Performance\n",
      "--------------------------------------------------------------------------------\n",
      "File DatasetLinJIRA. Label = p. Precision = 0.97. Recall = 0.84. F1 = 0.90\n",
      "File DatasetLinJIRA. Label = n. Precision = 0.93. Recall = 0.99. F1 = 0.96\n",
      "File = DatasetLinJIRA. F1 Macro = 0.93. Micro = 0.94\n",
      "-------------------------------\n",
      "File BenchmarkUddinSO. Label = p. Precision = 0.47. Recall = 0.15. F1 = 0.23\n",
      "File BenchmarkUddinSO. Label = o. Precision = 0.62. Recall = 0.91. F1 = 0.74\n",
      "File BenchmarkUddinSO. Label = n. Precision = 0.42. Recall = 0.17. F1 = 0.24\n",
      "File = BenchmarkUddinSO. F1 Macro = 0.45. Micro = 0.59\n",
      "-------------------------------\n",
      "File DatasetLinAppReviews. Label = p. Precision = 0.80. Recall = 0.91. F1 = 0.85\n",
      "File DatasetLinAppReviews. Label = o. Precision = 0.07. Recall = 0.04. F1 = 0.05\n",
      "File DatasetLinAppReviews. Label = n. Precision = 0.82. Recall = 0.73. F1 = 0.77\n",
      "File = DatasetLinAppReviews. F1 Macro = 0.56. Micro = 0.78\n",
      "-------------------------------\n",
      "File DatasetLinSO. Label = p. Precision = 0.53. Recall = 0.31. F1 = 0.39\n",
      "File DatasetLinSO. Label = o. Precision = 0.85. Recall = 0.95. F1 = 0.90\n",
      "File DatasetLinSO. Label = n. Precision = 0.61. Recall = 0.35. F1 = 0.45\n",
      "File = DatasetLinSO. F1 Macro = 0.59. Micro = 0.82\n",
      "-------------------------------\n",
      "File DatasetSenti4SDSO. Label = p. Precision = 0.87. Recall = 0.91. F1 = 0.89\n",
      "File DatasetSenti4SDSO. Label = o. Precision = 0.78. Recall = 0.84. F1 = 0.81\n",
      "File DatasetSenti4SDSO. Label = n. Precision = 0.83. Recall = 0.69. F1 = 0.76\n",
      "File = DatasetSenti4SDSO. F1 Macro = 0.82. Micro = 0.83\n",
      "-------------------------------\n",
      "File OrtuJIRA. Label = p. Precision = 0.79. Recall = 0.77. F1 = 0.78\n",
      "File OrtuJIRA. Label = o. Precision = 0.87. Recall = 0.92. F1 = 0.90\n",
      "File OrtuJIRA. Label = n. Precision = 0.85. Recall = 0.64. F1 = 0.73\n",
      "File = OrtuJIRA. F1 Macro = 0.81. Micro = 0.85\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "infile = os.path.join(indir, \"ConsolidatedWithBestTrainedClfsFromThreeSETools.xls\")\n",
    "learnerCol = \"SentiCR\"\n",
    "print learnerCol, \": Overall Performance\"\n",
    "print \"-\"*80\n",
    "computePerformanceOverallOfLearner(infile, learnerCol, filenames)    \n",
    "print learnerCol, \": By File Performance\"\n",
    "print \"-\"*80\n",
    "computePerformancOfLearner(infile, learnerCol, filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentistrengthSE : Overall Performance\n",
      "--------------------------------------------------------------------------------\n",
      "Label = p. Precision = 0.752. Recall = 0.690. F1 = 0.720\n",
      "Label = o. Precision = 0.750. Recall = 0.847. F1 = 0.795\n",
      "Label = n. Precision = 0.736. Recall = 0.566. F1 = 0.640\n",
      "F1 Macro = 0.723. Micro = 0.748\n",
      "Macro Precision = 0.746. Recall = 0.701\n",
      "-------------------------------\n",
      "SentistrengthSE : By File Performance\n",
      "--------------------------------------------------------------------------------\n",
      "File DatasetLinJIRA. Label = p. Precision = 0.95. Recall = 0.99. F1 = 0.97\n",
      "File DatasetLinJIRA. Label = n. Precision = 1.00. Recall = 0.97. F1 = 0.98\n",
      "File = DatasetLinJIRA. F1 Macro = 0.98. Micro = 0.98\n",
      "-------------------------------\n",
      "File BenchmarkUddinSO. Label = p. Precision = 0.49. Recall = 0.22. F1 = 0.31\n",
      "File BenchmarkUddinSO. Label = o. Precision = 0.63. Recall = 0.89. F1 = 0.74\n",
      "File BenchmarkUddinSO. Label = n. Precision = 0.43. Recall = 0.15. F1 = 0.23\n",
      "File = BenchmarkUddinSO. F1 Macro = 0.46. Micro = 0.60\n",
      "-------------------------------\n",
      "File DatasetLinAppReviews. Label = p. Precision = 0.74. Recall = 0.82. F1 = 0.78\n",
      "File DatasetLinAppReviews. Label = o. Precision = 0.11. Recall = 0.40. F1 = 0.17\n",
      "File DatasetLinAppReviews. Label = n. Precision = 0.93. Recall = 0.30. F1 = 0.45\n",
      "File = DatasetLinAppReviews. F1 Macro = 0.55. Micro = 0.59\n",
      "-------------------------------\n",
      "File DatasetLinSO. Label = p. Precision = 0.31. Recall = 0.22. F1 = 0.26\n",
      "File DatasetLinSO. Label = o. Precision = 0.82. Recall = 0.93. F1 = 0.87\n",
      "File DatasetLinSO. Label = n. Precision = 0.49. Recall = 0.18. F1 = 0.26\n",
      "File = DatasetLinSO. F1 Macro = 0.49. Micro = 0.78\n",
      "-------------------------------\n",
      "File DatasetSenti4SDSO. Label = p. Precision = 0.91. Recall = 0.82. F1 = 0.86\n",
      "File DatasetSenti4SDSO. Label = o. Precision = 0.73. Recall = 0.79. F1 = 0.75\n",
      "File DatasetSenti4SDSO. Label = n. Precision = 0.76. Recall = 0.76. F1 = 0.76\n",
      "File = DatasetSenti4SDSO. F1 Macro = 0.79. Micro = 0.79\n",
      "-------------------------------\n",
      "File OrtuJIRA. Label = p. Precision = 0.69. Recall = 0.92. F1 = 0.78\n",
      "File OrtuJIRA. Label = o. Precision = 0.92. Recall = 0.82. F1 = 0.87\n",
      "File OrtuJIRA. Label = n. Precision = 0.68. Recall = 0.73. F1 = 0.71\n",
      "File = OrtuJIRA. F1 Macro = 0.79. Micro = 0.83\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "infile = os.path.join(indir, \"ConsolidatedWithBestTrainedClfsFromThreeSETools.xls\")\n",
    "learnerCol = \"SentistrengthSE\"\n",
    "print learnerCol, \": Overall Performance\"\n",
    "print \"-\"*80\n",
    "computePerformanceOverallOfLearner(infile, learnerCol, filenames)    \n",
    "print learnerCol, \": By File Performance\"\n",
    "print \"-\"*80\n",
    "computePerformancOfLearner(infile, learnerCol, filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
